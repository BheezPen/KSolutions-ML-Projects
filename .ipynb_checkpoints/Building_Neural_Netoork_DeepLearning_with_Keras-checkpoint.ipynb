{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ee42fd7-6246-4dd7-b09e-4ee2d0c0ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import boston_housing #Importing the builting dataset to be used\n",
    "\n",
    "from sklearn import preprocessing #To help in processing the training and testing dateset  \n",
    "\n",
    "from keras.models import Sequential #This helps to crate a model\n",
    "\n",
    "from keras.layers import Dense #Dense is the name of the layers we would be using today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bdd557-1443-4faa-b7ca-dc2d9a47b64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Note, Keras do have 2 backend it can use, one is the Tensoflow, the other is Theano.\n",
    "### This backends, are import we know when working on a project with keras\n",
    "### The check the ackend here\n",
    "\n",
    "from keras import backend as bk\n",
    "bk.backend() #As below, i prints Tensorflow, telling thats the backend we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c4ec7f-f9b0-44b9-bd09-19caab99fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57026/57026 [==============================] - 0s 5us/step\n"
     ]
    }
   ],
   "source": [
    "# Now lets import the boston_housing dataset\n",
    "\n",
    "(x_train, y_train) , (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e8da544-f2b2-4fd5-bbae-0421fdf7e135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
       "        3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
       "        3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        3.75520e+02, 3.26000e+00],\n",
       "       ...,\n",
       "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
       "        3.62250e+02, 7.83000e+00],\n",
       "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.61950e+02, 1.57900e+01],\n",
       "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
       "        3.76700e+02, 4.38000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1622553c-cfb7-4802-a961-fa81c4e4559f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c55d240-5838-4bef-9a04-49d6cf6eb5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80846e+01, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        2.72500e+01, 2.90500e+01],\n",
       "       [1.23290e-01, 0.00000e+00, 1.00100e+01, ..., 1.78000e+01,\n",
       "        3.94950e+02, 1.62100e+01],\n",
       "       [5.49700e-02, 0.00000e+00, 5.19000e+00, ..., 2.02000e+01,\n",
       "        3.96900e+02, 9.74000e+00],\n",
       "       ...,\n",
       "       [1.83377e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        3.89610e+02, 1.92000e+00],\n",
       "       [3.58090e-01, 0.00000e+00, 6.20000e+00, ..., 1.74000e+01,\n",
       "        3.91700e+02, 9.71000e+00],\n",
       "       [2.92400e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.40160e+02, 9.81000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85730d0d-85f9-4ae1-b205-8c301b466971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.2, 18.8, 19. , 27. , 22.2, 24.5, 31.2, 22.9, 20.5, 23.2, 18.6,\n",
       "       14.5, 17.8, 50. , 20.8, 24.3, 24.2, 19.8, 19.1, 22.7, 12. , 10.2,\n",
       "       20. , 18.5, 20.9, 23. , 27.5, 30.1,  9.5, 22. , 21.2, 14.1, 33.1,\n",
       "       23.4, 20.1,  7.4, 15.4, 23.8, 20.1, 24.5, 33. , 28.4, 14.1, 46.7,\n",
       "       32.5, 29.6, 28.4, 19.8, 20.2, 25. , 35.4, 20.3,  9.7, 14.5, 34.9,\n",
       "       26.6,  7.2, 50. , 32.4, 21.6, 29.8, 13.1, 27.5, 21.2, 23.1, 21.9,\n",
       "       13. , 23.2,  8.1,  5.6, 21.7, 29.6, 19.6,  7. , 26.4, 18.9, 20.9,\n",
       "       28.1, 35.4, 10.2, 24.3, 43.1, 17.6, 15.4, 16.2, 27.1, 21.4, 21.5,\n",
       "       22.4, 25. , 16.6, 18.6, 22. , 42.8, 35.1, 21.5, 36. , 21.9, 24.1,\n",
       "       50. , 26.7, 25. ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f286ac-6143-4232-b7e8-488b4777ff2a",
   "metadata": {},
   "source": [
    "### SO, now beacuse data that's used in training of the neural networks are mostly very unstructured\n",
    "### Imagine a data from images to find pattern in the images so as to classify them\n",
    "### or data from videos\n",
    "### Surely they are so unstructured, and very random\n",
    "### to get the accuracy and predition somehow right, it will be necessary to use some sort of Processors & Transformers\n",
    "### i.e scikit-learn processor to be able to ensure that the training data and the test data are somewhat uniform. (i.e of same type)\n",
    "### This comformity and uniformity of both data is done before the learning and training process\n",
    "### Think of it like, before you starting test me with examination in school, we need to agree that before the teaching \n",
    "### So, with the agreement, i can followup with the teaching and training to prepare for examination (prediction in this case)\n",
    "### Between that is when the Uniforminity and Conformity comes in, the teaching must be uniform with the examination, right?\n",
    "### This process is very important in neural network beacause all data are quite random, so we have to ensure that thinkgs go as expected between the traning and testung data\n",
    "\n",
    "## All this process of reachign agreement between Training Data and Testing Data is called PROCESSING from sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe2a56aa-c245-4d40-9b77-c21985b6f4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO process the data here\n",
    "scale_x_train = preprocessing.scale(x_train) #THis scale out the x_train data\n",
    "\n",
    "#AFter scaling out, we convert it out to scaler\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "#The StandardScaler wil Standardize features by removing the mean and scaling to unit variance\n",
    "# return like the standdard deviation, mean deviation, \n",
    "# then the fit() Compute the mean and std to be used for later scaling\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b8e7eb1-2257-4de3-9cc8-e6340adc8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next is to scale the x_test\n",
    "scale_x_test = scaler.transform(x_test)\n",
    "# SO, with all of this done, in a nutshell, the trainign data has been normalized with the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28059e73-715e-4e70-9c30-2fca8157e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets create our model.\n",
    "\n",
    "my_model = Sequential() #Instantaiting the model from sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14714444-b955-46fc-a64d-367324ed81a9",
   "metadata": {},
   "source": [
    "## Now lets start adding layers to our model\n",
    "\n",
    "my_model.add(Dense(no_of_features, kernel_initializers)) <br/>\n",
    "\n",
    "In this case, the add method adds a layer instance on top of the layer stack <br/>\n",
    "In this case, dense is the name of a layer, there are several of it. <br/>\n",
    "Here, using it as the input layer of the neural model <br/>\n",
    "The dense takes a parameter which serve as the number of features in the dataset.  <br/>\n",
    "Bcus in most cases, the number of features isn't constant <br/>\n",
    "and even because, in some cases, the dataset isnt even known, we dont see it, since its a neural network that learn by itself, <br/>\n",
    "Then how do we know the number of features??? <br/>\n",
    "Well, while thats the standard, there are other rule of thumb that tells what should be used, maybe 32, maybe 64 <br/>\n",
    "But in this case lets use 64 <br/>\n",
    "no_of_features = 64 <br/>\n",
    "\n",
    "## Adding a layer ##\n",
    "my_model.add(Dense(no_of_features, kernel_initializer = 'normal', activators = )) <br/>\n",
    "kernel_initializer means that, when inputs are coming in in matrixs, its initilize the value of the them, it could be zero, or it could be one <br/>\n",
    "Some possible value for kernel_initializer variable is \"normal\" which is default,  another is 'glorot_uniform' suitable for most cases <br/>\n",
    "Another is 'he_normal' which is effective for deep networks with ReLU activation function (ReLU to be explained later)  <br/>\n",
    "\n",
    "## Another parameter is the activator, which help to determine the kind of inputs should be used.\n",
    "After several data are coming in as inputs, in used in the inout layer, the activators check through them and pick which is to be picked depends on the kind of activator that is to be used. <br/>\n",
    "In neural networks, they are like a decision maker for each neuron in the network. \n",
    "it decides whether the neuron should pass information to the next layer of neurons <br/>\n",
    "From the several of this activator, we have the <br/>\n",
    "- Sigmoid: Imagine it as a switch that can be either OFF (0) or ON (1). It's good for making yes/no decisions, like whether an email is spam or not. However, it's not great for very deep networks.\n",
    "- \r\n",
    "ReLU (Rectified Linear Unit): Think of it as a light switch that's either OFF (0) or ON (positive number)It set all negative values to Zero and is computationally efficient. . It's the most popular because it's simple and works well in many cases, like recognizing shapes in image ReLU helps mitigate the vanishing gradient problem but can suffer from 'dying Relu' issues when neurons get stuck at Zero during training.s- \r\n",
    "\r\n",
    "Leaky ReLU: Similar to ReLU, but if the light switch is OFF, there's a tiny bit of light (a small positive numbeit his headdresses the dying Reluvent problby allowing a small gradient for negative values whch helps avoid neurons becoming inactive ems in deep networ- s.\r\n",
    "\r\n",
    "ELU (Exponential Linear Unit): Like Leaky ReLU, but the light switch being OFF isn't pitch black; it's a bit br which hThis helps training even it has a non-zero gradient for negative values which can help with convergence and robustness - ore.\r\n",
    "\r\n",
    "Tanh (Hyperbolic Tangent): Imagine it like a thermometer that can show temperatures from -1 to 1. It's useful for data centered around zero, like when predicting if a stock will go up  though kinde suffers from vanishing gradientso-  down.\r\n",
    "\r\n",
    "Softmax: This one is like dividing a pie into slices, where each slice shows the probability of something happening. It's often used to decide which of many things is mo to add, its primarily used in the outlayer for multiclass classification.s-  likely.\r\n",
    "\r\n",
    "Swish: Think of Swish as a fancy light dimmer switch that works well in many situations but isn't as popu its kinda promising in lots of scenerio, and striking a balance between Relu and sigmoid-like functionsl- r as ReLU.\r\n",
    "\r\n",
    "GELU (Gaussian Error Linear Unit): This one is like a special tool used in some situations, like understanding the meaning of words  It sused in tranformer-based models and effective in NLP tasks\n",
    "  in a sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44bea0-f506-49bb-a81a-e234ec555d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_features = 64 <br/>\n",
    "\n",
    "## Adding a layer ##\n",
    "my_model.add(Dense(no_of_features, kernel_initializer = 'normal', activators = ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
